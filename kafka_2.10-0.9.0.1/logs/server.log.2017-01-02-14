[2017-01-02 14:09:36,254] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-01-02 14:09:36,260] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-01-02 14:09:36,260] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2017-01-02 14:09:36,552] INFO re-registering broker info in ZK for broker 0 (kafka.server.KafkaHealthcheck)
[2017-01-02 14:09:36,553] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-01-02 14:09:36,554] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-01-02 14:09:36,554] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(patrick,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[2017-01-02 14:09:36,555] INFO done re-registering broker (kafka.server.KafkaHealthcheck)
[2017-01-02 14:09:36,555] INFO Subscribing to /brokers/topics path to watch for new topics (kafka.server.KafkaHealthcheck)
[2017-01-02 14:09:36,749] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,28],[flink-winagg551232,0],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,41],[__consumer_offsets,0],[__consumer_offsets,38],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,37],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,27],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,31],[__consumer_offsets,18],[__consumer_offsets,19],[__consumer_offsets,12],[flink-winagg323123,0],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[2017-01-02 14:09:36,770] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2017-01-02 14:10:07,917] INFO [Group Metadata Manager on Broker 0]: Removed 1 expired offsets in 8 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2017-01-02 14:20:07,919] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 9 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2017-01-02 14:30:07,909] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2017-01-02 14:40:07,909] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2017-01-02 14:50:07,909] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2017-01-02 14:57:29,282] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2017-01-02 14:57:29,283] INFO [KafkaApi-0] Auto creation of topic spark-winagg551 with 1 partitions and replication factor 1 is successful! (kafka.server.KafkaApis)
[2017-01-02 14:57:29,646] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [spark-winagg551,0] (kafka.server.ReplicaFetcherManager)
[2017-01-02 14:57:29,651] INFO Completed load of log spark-winagg551-0 with log end offset 0 (kafka.log.Log)
[2017-01-02 14:57:29,651] INFO Created log for partition [spark-winagg551,0] in /tmp/kafka-logs with properties {compression.type -> producer, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-01-02 14:57:29,655] INFO Partition [spark-winagg551,0] on broker 0: No checkpointed highwatermark is found for partition [spark-winagg551,0] (kafka.cluster.Partition)
[2017-01-02 14:59:01,914] INFO Rolled new log segment for 'spark-winagg551-0' in 3 ms. (kafka.log.Log)
